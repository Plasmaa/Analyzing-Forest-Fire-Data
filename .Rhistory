install.packages("tidyverse")
library(tidyverse)
chickens <- read_csv("chickens.csv")
chickens <- read_csv("chickens.csv")
chickens
spec(chickens)
chickens <- read_csv(
readr_example("chickens.csv"),
col_types = cols(
chicken = col_character(),
sex = col_factor(levels = c("rooster", "hen")),
eggs_laid = col_integer(),
motto = col_character()
)
)
chickens
spec(chickens)
library(readxl)
people <- read_excel("people.xlsx")
people
people <- read_excel("people.xlsx", sheet= 2, range = "A5:F15")
people
employee <- read_excel("incidents.xlsx", sheet= 2, range = "b4:n30")
employee
i
table1
table 2
table2
table4a
table4a %>%
pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
table2 %>% head()
load("~/.RData")
nrow(installed.packages())
table4a
install.packages("tidyverse")
library(tidyverse)
chickens <- read_csv("chickens.csv")
chickens <- read_csv("chickens.csv")
chickens
spec(chickens)
chickens <- read_csv(
readr_example("chickens.csv"),
col_types = cols(
chicken = col_character(),
sex = col_factor(levels = c("rooster", "hen")),
eggs_laid = col_integer(),
motto = col_character()
)
)
chickens
spec(chickens)
library(readxl)
people <- read_excel("people.xlsx")
people
people <- read_excel("people.xlsx", sheet= 2, range = "A5:F15")
people
employee <- read_excel("incidents.xlsx", sheet= 2, range = "b4:n30")
employee
i
table4a
Sys.setenv(JAVA_HOME='C:\Program Files\Java\jdk-24')
Sys.setenv(JAVA_HOME='C:\program Files\Java\jdk-24')
cat("Loading my essential R packages...\n\n")
# List of the main packages I use
my_packages <- c(
"tidyverse",    # Includes ggplot2, dplyr, tidyr, readr, purrr, tibble, etc.
"caret",        # For machine learning and model training
"data.table",   # Fast data manipulation
"randomForest", # For Random Forest models
"rvest",        # For web scraping
"httr",         # For working with web APIs
"lubridate",    # For working with dates and times
"readxl",       # To read Excel files (.xls and .xlsx)
"xlsx",         # To read and write Excel files (Java-based)
"googlesheets4",# To interact with Google Sheets
"pROC",         # For ROC curve analysis
"car",          # Companion to Applied Regression
"rmarkdown",    # For creating reports and documents
"shiny"         # You have shiny-related packages, assuming you might use this
)
# Load all packages from the list
lapply(my_packages, library, character.only = TRUE)
Sys.setenv(JAVA_HOME='C:\Program Files\Java\jdk-24')
Sys.setenv(JAVA_HOME='C:/Program Files/Java/jdk-24')
library(xlsx)
install.packages("xlsxjars")
library(xlsx)
data<-read.xlsx(“mtcars.xlsx”,sheetIndex=1)
data<-read.xlsx("mtcars.xlsx",sheetIndex=1)
data1<-mtcars[,c("mpg","disp","hp","wt")]
View(data1)
install.packages(“psych”)
install.packages("psych")
library("psych")
corr.test(data1)
linear_model<-lm(mpg~disp+hp+wt,data=data1)
print(linear_model)
summary(linear_model)
hist(linear_model$residuals,col=75)
install.packages(“nortest”)
install.packages("nortest")
library("nortest")
ad.test(linear_model$residuals)
par(mfrow = c(2, 2))
plot(linear_model)
confint(linear_model)
find<-data.frame(disp=150,hp=170,wt=3.089)
predict(linear_model,find)
library(recommenderlab)
install.packages("recommenderlab")
library(recommenderlab)
library(ggplot2)                       #Author DataFlair
library(data.table)
library(reshape2)
library(ggplot2)
library(data.table)
library(reshape2)
setwd("C:\Users\Plasma\Documents")
setwd("C:/Users/Plasma/Documents")
setwd("E:/Code/0.1.Courses/AI")
setwd("~/")
setwd("C:/Users/Plasma/Documents")
movie_data <- read.csv("movies.csv",stringsAsFactors=FALSE)
rating_data <- read.csv("ratings.csv")
str(movie_data)
summary(movie_data)
head(movie_data)
summary(rating_data)
head(rating_data)
movie_genre <- as.data.frame(movie_data$genres, stringsAsFactors=FALSE)
library(data.table)
movie_genre2 <- as.data.frame(tstrsplit(movie_genre[,1], '[|]',
type.convert=TRUE),
stringsAsFactors=FALSE)
colnames(movie_genre2) <- c(1:10)
list_genre <- c("Action", "Adventure", "Animation", "Children",
"Comedy", "Crime","Documentary", "Drama", "Fantasy",
"Film-Noir", "Horror", "Musical", "Mystery","Romance",
"Sci-Fi", "Thriller", "War", "Western")
genre_mat1 <- matrix(0,10330,18)
genre_mat1[1,] <- list_genre
colnames(genre_mat1) <- list_genre
for (index in 1:nrow(movie_genre2)) {
for (col in 1:ncol(movie_genre2)) {
gen_col = which(genre_mat1[1,] == movie_genre2[index,col]) #Author DataFlair
genre_mat1[index+1,gen_col] <- 1
}
genre_mat2 <- as.data.frame(genre_mat1[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (col in 1:ncol(genre_mat2)) {
genre_mat2[,col] <- as.integer(genre_mat2[,col]) #convert from characters to integers
}
str(genre_mat2)
movie_genre <- as.data.frame(movie_data$genres, stringsAsFactors=FALSE)
library(data.table)
movie_genre2 <- as.data.frame(tstrsplit(movie_genre[,1], '[|]',
type.convert=TRUE),
stringsAsFactors=FALSE) #DataFlair
colnames(movie_genre2) <- c(1:10)
list_genre <- c("Action", "Adventure", "Animation", "Children",
"Comedy", "Crime","Documentary", "Drama", "Fantasy",
"Film-Noir", "Horror", "Musical", "Mystery","Romance",
"Sci-Fi", "Thriller", "War", "Western")
genre_mat1 <- matrix(0,10330,18)
genre_mat1[1,] <- list_genre
colnames(genre_mat1) <- list_genre
for (index in 1:nrow(movie_genre2)) {
for (col in 1:ncol(movie_genre2)) {
gen_col = which(genre_mat1[1,] == movie_genre2[index,col]) #Author DataFlair
genre_mat1[index+1,gen_col] <- 1
}
}
genre_mat2 <- as.data.frame(genre_mat1[-1,], stringsAsFactors=FALSE) #remove first row, which was the genre list
for (col in 1:ncol(genre_mat2)) {
genre_mat2[,col] <- as.integer(genre_mat2[,col]) #convert from characters to integers
}
str(genre_mat2)
View(movie_genre)
View(movie_genre2)
SearchMatrix <- cbind(movie_data[,1:2], genre_mat2[])
head(SearchMatrix)
}
SearchMatrix <- cbind(movie_data[,1:2], genre_mat2[])
head(SearchMatrix)
ratingMatrix <- dcast(rating_data, userId~movieId, value.var = "rating", na.rm=FALSE)
ratingMatrix <- as.matrix(ratingMatrix[,-1])
#Convert rating matrix into a recommenderlab sparse matrix
ratingMatrix <- as(ratingMatrix, "realRatingMatrix")
ratingMatrix
recommendation_model <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommendation_model)
lapply(recommendation_model, "[[", "description")
recommendation_model$IBCF_realRatingMatrix$parameters
similarity_mat <- similarity(ratingMatrix[1:4, ],
method = "cosine",
which = "users")
as.matrix(similarity_mat)
image(as.matrix(similarity_mat), main = "User's Similarities")
movie_similarity <- similarity(ratingMatrix[, 1:4], method =
"cosine", which = "items")
as.matrix(movie_similarity)
image(as.matrix(movie_similarity), main = "Movies similarity")
rating_values <- as.vector(ratingMatrix@data)
unique(rating_values)
Table_of_Ratings <- table(rating_values) # creating a count of movie ratings
Table_of_Ratings
library(ggplot2)
movie_views <- colCounts(ratingMatrix) # count views for each movie
table_views <- data.frame(movie = names(movie_views),
views = movie_views) # create dataframe of views
table_views <- table_views[order(table_views$views,
decreasing = TRUE), ] # sort by number of views
table_views$title <- NA
for (index in 1:10325){
table_views[index,3] <- as.character(subset(movie_data,
movie_data$movieId == table_views[index,1])$title)
}
library(ggplot2)
movie_views <- colCounts(ratingMatrix)
table_views <- data.frame(movie = names(movie_views),
views = movie_views)
table_views <- table_views[order(table_views$views, decreasing = TRUE), ] table_views$title <- NA
table_views <- table_views[order(table_views$views,
decreasing = TRUE), ] # sort by number of views
table_views$title <- NA
for (index in 1:10325){
table_views[index,3] <- as.character(subset(movie_data,
movie_data$movieId == table_views[index,1])$title)
}
table_views[1:6,]
ggplot(table_views[1:6, ], aes(x = title, y = views)) +
geom_bar(stat="identity", fill = 'steelblue') +
geom_text(aes(label=views), vjust=-0.3, size=3.5) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
ggtitle("Total Views of the Top Films")
image(ratingMatrix[1:20, 1:25], axes = FALSE, main = "Heatmap of the first 25 rows and 25 columns")
movie_ratings <- ratingMatrix[rowCounts(ratingMatrix) > 50,
colCounts(ratingMatrix) > 50]
Movie_ratings
movie_ratings <- ratingMatrix[rowCounts(ratingMatrix) > 50,
colCounts(ratingMatrix) > 50]
Movie_ratings
movie_ratings <- ratingMatrix[rowCounts(ratingMatrix) > 50,
colCounts(ratingMatrix) > 50]
movie_ratings <- ratingMatrix[rowCounts(ratingMatrix) > 50, colCounts(ratingMatrix) > 50]
movie_ratings
minimum_movies<- quantile(rowCounts(movie_ratings), 0.98)
minimum_users <- quantile(colCounts(movie_ratings), 0.98)
image(movie_ratings[rowCounts(movie_ratings) > minimum_movies,
colCounts(movie_ratings) > minimum_users],
main = "Heatmap of the top users and movies")
average_ratings <- rowMeans(movie_ratings)
qplot(average_ratings, fill=I("steelblue"), col=I("red")) +
ggtitle("Distribution of the average rating per user")
normalized_ratings <- normalize(movie_ratings)
sum(rowMeans(normalized_ratings) > 0.00001)
image(normalized_ratings[rowCounts(normalized_ratings) > minimum_movies,
colCounts(normalized_ratings) > minimum_users],
main = "Normalized Ratings of the Top Users")
binary_minimum_movies <- quantile(rowCounts(movie_ratings), 0.95)
binary_minimum_users <- quantile(colCounts(movie_ratings), 0.95)
#movies_watched <- binarize(movie_ratings, minRating = 1)
good_rated_films <- binarize(movie_ratings, minRating = 3)
image(good_rated_films[rowCounts(movie_ratings) > binary_minimum_movies,
colCounts(movie_ratings) > binary_minimum_users],
main = "Heatmap of the top users and movies")
sampled_data<- sample(x = c(TRUE, FALSE),
size = nrow(movie_ratings),
replace = TRUE,
prob = c(0.8, 0.2))
training_data <- movie_ratings[sampled_data, ]
testing_data <- movie_ratings[!sampled_data, ]
recommendation_system <- recommenderRegistry$get_entries(dataType ="realRatingMatrix")
recommendation_system$IBCF_realRatingMatrix$parameters
recommen_model <- Recommender(data = training_data,
method = "IBCF",
parameter = list(k = 30))
recommen_model
class(recommen_model)
model_info <- getModel(recommen_model)
class(model_info$sim)
dim(model_info$sim)
top_items <- 20
image(model_info$sim[1:top_items, 1:top_items],
main = "Heatmap of the first rows and columns")
sum_rows <- rowSums(model_info$sim > 0)
table(sum_rows)
sum_cols <- colSums(model_info$sim > 0)
qplot(sum_cols, fill=I("steelblue"), col=I("red"))+ ggtitle("Distribution of the column count")
top_recommendations <- 10 # the number of items to recommend to each user
predicted_recommendations <- predict(object = recommen_model,
newdata = testing_data,
n = top_recommendations)
predicted_recommendations
user1 <- predicted_recommendations@items[[1]] # recommendation for the first user
movies_user1 <- predicted_recommendations@itemLabels[user1]
movies_user2 <- movies_user1
for (index in 1:10){
movies_user2[index] <- as.character(subset(movie_data,
movie_data$movieId == movies_user1[index])$title)
}
movies_user2
recommendation_matrix <- sapply(predicted_recommendations@items,
function(x){ as.integer(colnames(movie_ratings)[x]) }) # matrix with the recommendations for each user
#dim(recc_matrix)
recommendation_matrix[,1:4]
dim(recc_matrix)
library(tidytext)
install.packages("tidytext")
Sentiments
library(tidytext)
sentiments
get_sentiments("bing")
library(janeaustenr)
library(stringr)
library(tidytext)
tidy_data <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
ungroup() %>%
unnest_tokens(word, text)
library(dplyr)
ungroup() %>%
unnest_tokens(word, text)
library(janeaustenr)
library(stringr)
library(tidytext)
library(dplyr) # <-- Add this line
tidy_data <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
positive_senti <- get_sentiments("bing") %>%
filter(sentiment == "positive")
tidy_data %>%
filter(book == "Emma") %>%
semi_join(positive_senti) %>%
count(word, sort = TRUE)
library(tidyr)
bing <- get_sentiments("bing")
Emma_sentiment <- tidy_data %>%
inner_join(bing) %>%
count(book = "Emma" , index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
library(ggplot2)
ggplot(Emma_sentiment, aes(index, sentiment, fill = book)) +
geom_bar(stat = "identity", show.legend = TRUE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
counting_words <- tidy_data %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE)
head(counting_words)
counting_words %>%
filter(n > 150) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment))+
geom_col() +
coord_flip() +
labs(y = "Sentiment Score")
library(reshape2)
library(wordcloud)
install.packages("wordcloud")
library(reshape2)
library(wordcloud)
tidy_data %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "dark green"),
max.words = 100)
library(tidyverse)
setwd("E:/Code/0.1.Courses/Advance Basic Data Analysis + Reasearch (edulink)/3.R/Project/Analyzing Forest Fire Data")
forest_fires <- read_csv("forestfires.csv")
# What columns are in the dataset?
colnames(forest_fires)
forest_fires %>% pull(month) %>% unique
forest_fires %>% pull(day) %>% unique
month_order <- c("jan", "feb", "mar",
"apr", "may", "jun",
"jul", "aug", "sep",
"oct", "nov", "dec")
dow_order <- c("sun", "mon", "tue", "wed", "thu", "fri", "sat")
forest_fires <- forest_fires %>%
mutate(
month = factor(month, levels = month_order),
day = factor(day, levels = dow_order)
)
fires_by_month <- forest_fires %>%
group_by(month) %>%
summarize(total_fires = n())
fires_by_month %>%
ggplot(aes(x = month, y = total_fires)) +
geom_col() +
labs(
title = "Number of forest fires in data by month",
y = "Fire count",
x = "Month"
)
fires_by_dow <- forest_fires %>%
group_by(day) %>%
summarize(total_fires = n())
fires_by_dow %>%
ggplot(aes(x = day, y = total_fires)) +
geom_col() +
labs(
title = "Number of forest fires in data by day of the week",
y = "Fire count",
x = "Day of the week"
)
forest_fires_long <- forest_fires %>%
pivot_longer(
cols = c("FFMC", "DMC", "DC",
"ISI", "temp", "RH",
"wind", "rain"),
names_to = "data_col",
values_to = "value"
)
forest_fires_long %>%
ggplot(aes(x = month, y = value)) +
geom_boxplot() +
facet_wrap(vars(data_col), scale = "free_y") +
labs(
title = "Variable changes over month",
x = "Month",
y = "Variable value"
)
forest_fires_long %>%
ggplot(aes(x = value, y = area)) +
geom_point() +
facet_wrap(vars(data_col), scales = "free_x") +
labs(
title = "Relationships between other variables and area burned",
x = "Value of column",
y = "Area burned (hectare)"
)
forest_fires_long %>%
filter(area < 300) %>%
ggplot(aes(x = value, y = area)) +
geom_point() +
facet_wrap(vars(data_col), scales = "free_x") +
labs(
title = "Relationships between other variables and area burned (area < 300)",
x = "Value of column",
y = "Area burned (hectare)"
)
load("E:/Code/0.1.Courses/Advance Basic Data Analysis + Reasearch (edulink)/3.R/Project/Analyzing Forest Fire Data/.RData")
